# СИИТ


### 1. Что входит в ключевые компоненты информационных технологий (ИТ)?
Ключевые компоненты ИТ образуют единую экосистему для работы с данными. Аппаратное обеспечение (hardware) — это физические устройства: серверы, компьютеры, сетевое оборудование и накопители. Программное обеспечение (software) включает операционные системы, приложения и утилиты, которые выполняются на hardware. Сети и телекоммуникации обеспечивают передачу данных между устройствами через проводные и беспроводные технологии. Данные — это центральный актив, сырая информация, которая обрабатывается и хранится. Наконец, человеческие ресурсы и процессы (кадры ИТ-специалистов и регламенты их работы) управляют всеми этими компонентами. Вместе они решают задачи по сбору, хранению, обработке и распространению информации.

### 2. Опишите архитектуру и основные принципы эры мейнфреймов (1960–1980).
Архитектура эры мейнфреймов строилась вокруг централизованного мощного компьютера (мейнфрейма). Пользователи взаимодействовали с системой через «тупые» терминалы, которые лишь отображали информацию и отправляли ввод. Все вычисления, хранение данных и управление производились централизованно на мейнфрейме. Ключевыми принципами были пакетная обработка задач и разделение времени (time-sharing). При пакетной обработке задания накапливались и выполнялись одно за другим. Time-sharing позволял множеству пользователей одновременно работать с системой, деля её вычислительные ресурсы. Эта модель обеспечивала высокую степень контроля, безопасности и эффективности использования дорогих ресурсов. Однако она создавала единую точку отказа и ограничивала гибкость для конечных пользователей.

### 3. В чём заключаются преимущества и недостатки клиент-серверной архитектуры?
**Преимущества:** Архитектура разделяет обязанности: сервер предоставляет ресурсы (данные, вычисления), а клиент их запрашивает и отображает. Это обеспечивает централизованное управление данными и безопасностью. Система легко масштабируется: можно увеличивать мощность сервера или добавлять новых клиентов. Разделение логики позволяет использовать разные технологии на стороне клиента и сервера. **Недостатки:** Сервер представляет собой единую точку отказа — его сбой парализует работу всех клиентов. Пиковые нагрузки на сервер могут приводить к снижению производительности для всех пользователей. Сетевая инфраструктура становится критически важной, а её отказ блокирует работу. Обслуживание и обновление серверной части часто требуют остановки всей системы, что влияет на доступность.

### 4. Что такое облачные вычисления и каков их ключевой принцип?
Облачные вычисления — это модель предоставления по требованию вычислительных ресурсов (серверы, хранилища, сети, приложения) через интернет. Пользователь получает доступ к пулу общих ресурсов, управляемых провайдером. Ключевой принцип — самообслуживание по требованию (on-demand self-service). Это означает, что потребитель может автоматически, без взаимодействия с провайдером, выделять и конфигурировать нужные ресурсы (например, запустить виртуальную машину за минуту). Другими важными принципами являются широкий доступ по сети, объединение ресурсов в пул (мультитенантность), эластичность (быстрое масштабирование) и измеряемость услуг (оплата по факту использования). Эта модель устраняет необходимость в предварительных крупных капитальных затратах (CapEx) на инфраструктуру.

### 5. Перечислите и охарактеризуйте три основные модели обслуживания в облаке: IaaS, PaaS, SaaS.
**IaaS (Infrastructure as a Service):** Провайдер предоставляет фундаментальные вычислительные ресурсы: виртуальные машины, сети, хранилища. Пользователь управляет ОС, приложениями и данными, сохраняя контроль над конфигурацией. Пример: Amazon EC2, Microsoft Azure VMs. **PaaS (Platform as a Service):** Предоставляет среду для разработки, запуска и управления приложениями. Провайдер отвечает за инфраструктуру, ОС, middleware. Разработчик фокусируется на коде приложения. Пример: Google App Engine, Heroku. **SaaS (Software as a Service):** Готовое приложение, работающее в облаке и доступное через браузер. Провайдер управляет всем стеком: инфраструктурой, ПО и данными. Пользователь лишь использует функционал. Пример: Gmail, Salesforce, Microsoft 365. Модели образуют стек: IaaS — основа, PaaS — платформа поверх неё, SaaS — готовый продукт.

### 6. Что такое контейнеризация и как Docker решает проблему переносимости приложений?
Контейнеризация — это технология упаковки приложения со всеми его зависимостями (библиотеки, настройки, переменные среды) в изолированный, легковесный исполняемый пакет — контейнер. Docker — ведущая платформа для создания и управления контейнерами. Он решает проблему переносимости через использование образов (images). Образ Docker — это неизменяемый шаблон, содержащий всё необходимое для запуска приложения. Поскольку контейнер работает поверх единого ядра ОС хоста, этот образ будет одинаково выполняться на любой системе, где установлен Docker (разработка, тестирование, продакшн), независимо от различий в конфигурации среды. Девиз «works on my machine» теряет актуальность.

### 7. Чем контейнер отличается от виртуальной машины?
Ключевое отличие — уровень абстракции и архитектура. **Виртуальная машина (VM)** эмулирует полноценный компьютер с собственным ядром операционной системы (гостевой ОС). Она работает поверх гипервизора, который делит физические ресурсы хоста. Это дает полную изоляцию, но требует значительных ресурсов и времени на запуск. **Контейнер** — это изолированный процесс, который делит ядро хостовой ОС с другими контейнерами. Он содержит только приложение и его зависимости, но не гостевую ОС. Это делает контейнеры невероятно легковесными, быстрыми в запуске и эффективными по использованию ресурсов. Однако они менее изолированы, чем VM, и все контейнеры на хосте должны быть совместимы с его ядром.

### 8. Что такое оркестрация контейнеров и для чего нужен Kubernetes?
Оркестрация контейнеров — это автоматизация развертывания, масштабирования, управления сетями и обеспечения отказоустойчивости для контейнеризированных приложений. Когда таких контейнеров сотни или тысячи, ручное управление ими становится невозможным. **Kubernetes (K8s)** — это ведущая система оркестрации с открытым исходным кодом. Она нужна для автоматического размещения контейнеров на кластере узлов, отслеживания их состояния и перезапуска при сбоях. Kubernetes масштабирует приложение в зависимости от нагрузки, управляет сетевым взаимодействием между сервисами и организует хранение данных. По сути, он предоставляет платформу для надежного и эффективного запуска микросервисов в распределенной среде.

### 9. Что такое Pod в Kubernetes и как он связан с контейнерами?
Pod — это наименьшая и простейшая единица развертывания в Kubernetes. Это не контейнер, а «обертка» для одного или нескольких тесно связанных контейнеров. Контейнеры внутри одного Pod разделяют сетевые пространства (имеют один IP-адрес) и хранилище (общие тома). Они всегда развертываются вместе на одном узле кластера. Например, Pod может содержать основной контейнер с приложением и sidecar-контейнер для логирования или синхронизации файлов. Pod обеспечивает единый контекст выполнения для своей группы контейнеров. Kubernetes управляет жизненным циклом Pod (создание, уничтожение), а не отдельных контейнеров напрямую. Это абстракция более высокого уровня.

### 10. Опишите роль Service в Kubernetes. Какие проблемы он решает?
Service в Kubernetes — это абстракция, которая определяет постоянную конечную точку для доступа к логической группе Pod. Основная проблема, которую он решает, — динамичность Pod'ов: они создаются, уничтожаются, перемещаются, меняя свои IP-адреса. Service предоставляет стабильный DNS-имя и виртуальный IP (ClusterIP), который не меняется. Он автоматически направляет трафик на все работающие Pod'ы, соответствующие селекторам меток (label selectors) Service, обеспечивая балансировку нагрузки. Это позволяет микросервисам находить и взаимодействовать друг с другом по имени, не заботясь о текущем расположении их экземпляров. Также Service может обеспечивать доступ к приложению извне кластера (типы NodePort, LoadBalancer).

### 11. Что такое машинное обучение (ML) и чем оно отличается от классического программирования?
Машинное обучение — это подраздел искусственного интеллекта, где системы учатся выполнять задачи, не будучи явно запрограммированными под них. Вместо написания жестких правил (как в классическом программировании) ML-инженер предоставляет алгоритму данные и задачу (например, «научись различать кошек и собак»). Алгоритм сам находит в данных закономерности (паттерны) и строит математическую модель. В классическом программировании: `Входные данные + Программа = Результат`. В машинном обучении: `Входные данные + Ожидаемый результат = Модель`. Затем эта обученная модель может применять найденные закономерности к новым, никогда не виденным данным, делая прогнозы или принимая решения.

### 12. Приведите примеры задач классификации и регрессии в машинном обучении.
**Классификация** — это задача предсказания дискретной категории (класса). Примеры: 1) Определение спама в электронной почте (классы: «спам» / «не спам»). 2) Распознавание рукописных цифр на изображении (классы: цифры от 0 до 9). 3) Диагностика заболевания по симптомам (классы: «болен» / «здоров» или конкретный диагноз). **Регрессия** — это задача предсказания непрерывного числового значения. Примеры: 1) Прогнозирование цены дома на основе его площади, местоположения и числа комнат. 2) Предсказание спроса на товар в следующем месяце. 3) Оценка времени доставки заказа на основе расстояния и трафика. Оба типа задач относятся к обучению с учителем, где модель обучается на размеченных данных.

### 13. В чём разница между обучением с учителем и без учителя? Приведите примеры.
**Обучение с учителем (Supervised Learning)** использует размеченные данные, где каждому примеру сопоставлен правильный ответ (метка). Цель — научиться предсказывать метку для новых данных. Примеры: классификация (определение тональности отзыва) и регрессия (прогноз стоимости акции). **Обучение без учителя (Unsupervised Learning)** работает с данными без заранее известных меток. Цель — обнаружить скрытую структуру, сходства или закономерности в данных. Примеры: кластеризация (сегментация клиентов по поведению), снижение размерности (PCA для визуализации сложных данных) и ассоциация (поиск часто покупаемых вместе товаров, как в «правиле бакалеи»). Есть также полуконтролируемое и обучение с подкреплением.

### 14. Что такое виртуализация и какие типы виртуализации вы знаете?
Виртуализация — это создание виртуальной (а не физической) версии ресурса: сервера, хранилища, сети или даже ОС. Она позволяет на одном физическом «хосте» запускать несколько изолированных «гостевых» сред (виртуальных машин). **Основные типы:** 1) **Аппаратная виртуализация (серверная):** Наиболее распространенный тип, когда гипервизор создает ВМ с полной гостевой ОС (например, VMware vSphere, Microsoft Hyper-V). 2) **Виртуализация на уровне ОС (контейнеризация):** Изоляция процессов в рамках одного ядра ОС (Docker, LXC). 3) **Виртуализация рабочих столов (VDI):** Запуск удаленных рабочих столов пользователей на центральном сервере (VMware Horizon, Citrix). 4) **Виртуализация сетей (NFV):** Абстрагирование сетевых функций от специализированного оборудования.

### 15. Чем гипервизор отличается от гостевой операционной системы?
**Гипервизор (монитор виртуальных машин)** — это программный слой, который напрямую работает на физическом аппаратном обеспечении (или поверх ОС хоста) и управляет распределением его ресурсов (CPU, RAM, диск) между виртуальными машинами. Он контролирует доступ к железу и обеспечивает изоляцию ВМ друг от друга. **Гостевая операционная система** — это обычная ОС (например, Windows или Linux), которая устанавливается *внутри* виртуальной машины, предоставленной гипервизором. Она «думает», что работает на реальном компьютере, и управляет приложениями пользователя внутри своей изолированной среды. Гипервизор — это хост, управляющий «квартирами» (ВМ), а гостевая ОС — это «жилец» внутри такой квартиры.

### 16. Назовите преимущества виртуализации для бизнеса.
1) **Консолидация серверов:** Увеличение утилизации оборудования за счет запуска множества ВМ на одном физическом сервере, что снижает затраты на железо, энергопотребление и площадь ЦОД. 2) **Высокая доступность и отказоустойчивость:** ВМ можно быстро переносить (live migration) между физическими хостами при сбоях или для обслуживания без простоя сервисов. 3) **Ускорение развертывания:** Шаблон ВМ можно клонировать за минуты, а не устанавливать ОС и ПО с нуля. 4) **Упрощение резервного копирования и восстановления:** ВМ — это файлы, которые легко копировать и восстанавливать. 5) **Безопасность и изоляция:** Приложения в разных ВМ изолированы, сбой одной не влияет на другие. 6) **Поддержка legacy-приложений:** Можно запускать старое ПО на подходящей версии гостевой ОС на современном железе.

### 17. Какие компании являются основными игроками на рынке виртуализации?
**VMware** — исторический лидер с продуктами vSphere (гипервизор ESXi), vCenter, NSX (сетевая виртуализация). **Microsoft** предлагает Hyper-V как компонент Windows Server и облачную платформу Azure с виртуализацией. **Citrix (ныне часть Cloud Software Group)** сильна в виртуализации рабочих столов и приложений (Citrix Virtual Apps and Desktops). **Red Hat (IBM)** продвигает открытые решения: KVM (гипервизор) и платформу управления Red Hat Virtualization. В сфере контейнеризации, которая является формой виртуализации ОС, доминируют **Docker** (контейнеры) и **Kubernetes** (оркестрация, поддерживаемая всеми крупными облачными провайдерами).

### 18. Что такое архитектура микросервисов и каковы её основные преимущества?
Архитектура микросервисов — это подход к разработке единого приложения как набора небольших, слабо связанных сервисов. Каждый сервис работает в собственном процессе и отвечает за одну бизнес-возможность (например, «управление заказами», «аутентификация пользователей»). Сервисы общаются через легковесные механизмы (часто HTTP/REST, gRPC или сообщения). **Преимущества:** 1) **Независимое развертывание:** Можно обновлять один сервис без перезапуска всего приложения. 2) **Гибкость технологий:** Каждый сервис можно писать на подходящем языке и использовать свою СУБД. 3) **Масштабируемость:** Можно масштабировать только узкие места, а не всё приложение целиком. 4) **Отказоустойчивость:** Сбой одного сервиса не обязательно приводит к падению всей системы. 5) **Упрощение понимания:** Каждая команда фокусируется на своем сервисе.

### 19. Какие недостатки есть у микросервисной архитектуры?
1) **Высокая сложность распределенной системы:** Появляются проблемы сетевых задержек, отказоустойчивости связи, транзакций и согласованности данных. 2) **Сложность эксплуатации (DevOps):** Требуется автоматизация развертывания, оркестрации, мониторинга сотен сервисов (необходимы Kubernetes, централизованное логирование, трассировка). 3) **Накладные расходы на межсервисное взаимодействие:** Сериализация/десериализация данных и сетевые вызовы медленнее, чем вызовы внутри процесса. 4) **Сложность тестирования и отладки:** Трудно воспроизвести окружение и отследить цепочку вызовов между сервисами. 5) **Проблемы с безопасностью:** Увеличивается поверхность атаки, требуется управление аутентификацией/авторизацией между сервисами. 6) **Потребность в зрелой командной культуре и инфраструктуре.**

### 20. Что такое Serverless (FaaS) и в каких случаях его стоит использовать?
Serverless (в частности, FaaS — Function as a Service) — это модель, где облачный провайдер динамически управляет выделением ресурсов для выполнения вашего кода. Разработчик просто загружает функцию (небольшой фрагмент кода), которая запускается в ответ на событие (HTTP-запрос, загрузка файла, таймер). Провайдер автоматически масштабирует её до тысяч параллельных выполнений. **Использовать стоит:** 1) Для событийно-управляемых задач с переменной или редкой нагрузкой (обработка webhook, реакция на изменения в БД). 2) Для фоновых задач (преобразование изображений, обработка очередей сообщений). 3) Для API бэкендов с непредсказуемым трафиком. 4) Когда не хочется управлять серверами и инфраструктурой. Главный плюс — оплата только за время выполнения функции (вплоть до миллисекунд).

### 21. Какие ограничения есть у Serverless-архитектуры?
1) **Холодный старт:** Задержка при первом вызове функции после простоя, пока провайдер подготавливает окружение. 2) **Ограничения на время выполнения:** Функции не могут выполняться бесконечно (обычно лимит 5-15 минут). 3) **Сложность с долгими задачами:** Не подходит для обработки видео, тяжелых вычислений, если они превышают таймаут. 4) **Сложность отладки и мониторинга:** Распределенное выполнение в бессерверной среде требует специализированных инструментов. 5) **Вендор-лок:** Сильная привязка к API и сервисам конкретного облачного провайдера (AWS Lambda, Azure Functions). 6) **Ограничения по памяти и CPU.** 7) **Сложности с локальным тестированием.** 8) **Проблемы с управлением состоянием:** Функции должны быть stateless, состояние нужно хранить во внешних сервисах.

### 22. Что такое гибридное облако и в чём его преимущества?
Гибридное облако — это комбинированная ИТ-инфраструктура, которая соединяет частное облако (или локальный ЦОД) с публичным облаком, позволяя данным и приложениям перемещаться между ними. Преимущества: 1) **Гибкость и масштабируемость:** Можно использовать публичное облако для обработки пиковых нагрузок (bursting), не расширяя локальные мощности. 2) **Оптимизация затрат:** Критичные и постоянные нагрузки работают локально, а переменные — в облаке с оплатой по факту. 3) **Безопасность и соответствие требованиям:** Чувствительные данные можно хранить в частном облаке, а менее критичные части приложения запускать публично. 4) **Плавная миграция:** Возможность постепенно переносить приложения в облако, не переписывая их полностью. Это требует единой платформы управления (например, VMware Cloud on AWS, Azure Arc).

### 23. Что такое мультиоблачная стратегия и зачем она нужна?
Мультиоблачная стратегия — это использование услуг двух или более публичных облачных провайдеров (например, AWS, Azure и Google Cloud одновременно) для различных задач или даже для одной распределенной системы. **Зачем она нужна:** 1) **Избегание вендор-лока:** Снижение зависимости от одного поставщика, усиление переговорной позиции. 2) **Выбор лучших в своем классе услуг:** Использование сильных сторон каждого провайдера (например, AI от Google, enterprise-интеграции от Azure). 3) **Повышение отказоустойчивости:** Географическое распределение и резервирование на случай сбоя у одного провайдера. 4) **Соответствие регуляторным требованиям:** Размещение данных в определенных регионах или у конкретных провайдеров. 5) **Результат слияний и поглощений:** Унаследованные системы уже могут находиться в разных облаках. Эта стратегия сложна в управлении и требует экспертизы.

### 24. Какие критерии выбора облачного провайдера вы можете назвать?
1) **Стоимость:** Структура тарифов, цены на нужные сервисы, стоимость исходящего трафика. 2) **Предлагаемые услуги (Service Portfolio):** Наличие и зрелость конкретных PaaS-сервисов (базы данных, AI/ML, IoT). 3) **Производительность и глобальное покрытие:** География регионов и зон доступности (AZ), задержки сети. 4) **Безопасность и соответствие требованиям:** Сертификаты (ISO, SOC, GDPR), инструменты шифрования, управления доступом. 5) **Интеграция с существующей ИТ-средой:** Поддержка гибридных сценариев (например, Direct Connect), совместимость с используемыми технологиями. 6) **Экосистема и сообщество:** Наличие партнеров, качество документации, активность сообщества. 7) **Уровень поддержки (SLA):** Гарантии доступности, время реакции техподдержки.

### 25. В чём разница между CapEx и OpEx в контексте облачных технологий?
**CapEx (Capital Expenditure, капитальные затраты)** — это крупные единовременные инвестиции в физические активы (серверы, сетевое оборудование, здание ЦОД), которые амортизируются годами. Традиционная локальная инфраструктура — это CapEx. **OpEx (Operational Expenditure, операционные расходы)** — это текущие расходы на бизнес-операции, которые списываются в том же периоде. Облачные вычисления переводят ИТ-затраты из CapEx в OpEx. Вместо покупки сервера (CapEx) вы арендуете виртуальную машину и платите ежемесячно по факту использования (OpEx). Это дает финансовую гибкость, снижает барьер входа и позволяет точно прогнозировать ИТ-бюджет, но может привести к росту затрат при неэффективном использовании ресурсов.

### 26. Что такое Dockerfile и для чего он используется?
Dockerfile — это текстовый файл с инструкциями для автоматической сборки образа Docker. Он содержит пошаговое описание того, как создать среду выполнения для вашего приложения. Каждая инструкция создает слой в конечном образе. **Основные инструкции:** `FROM` задает базовый образ (например, Ubuntu). `RUN` выполняет команды внутри контейнера (установка пакетов). `COPY` / `ADD` копируют файлы с хоста в образ. `WORKDIR` устанавливает рабочую директорию. `EXPOSE` указывает на какой порт слушает приложение. `CMD` или `ENTRYPOINT` определяют команду для запуска при старте контейнера. Исполняя команду `docker build -t myapp .`, Docker считывает Dockerfile и создает готовый, переносимый образ.

### 27. Какие основные команды Docker вы знаете? Опишите их назначение.
1) **`docker build -t name .`** — Собирает образ из Dockerfile в текущей директории. 2) **`docker run -d -p 80:80 image_name`** — Запускает контейнер из образа в фоновом режиме (`-d`) с пробросом порта. 3) **`docker ps`** — Показывает запущенные контейнеры. `docker ps -a` показывает все. 4) **`docker stop container_id`** — Останавливает контейнер. `docker start` — запускает остановленный. 5) **`docker rm container_id`** — Удаляет контейнер. `docker rmi image_id` удаляет образ. 6) **`docker exec -it container_id bash`** — Подключается к запущенному контейнеру в интерактивном режиме. 7) **`docker logs container_id`** — Показывает логи контейнера. 8) **`docker pull image_name`** — Скачивает образ из реестра (Docker Hub). 9) **`docker push image_name`** — Загружает свой образ в реестр.

### 28. Что такое ConfigMap и Secret в Kubernetes?
**ConfigMap** — это объект Kubernetes для хранения конфигурационных данных в виде пар «ключ-значение» (например, настройки, файлы конфигов) в *незашифрованном* виде. Он позволяет отделить конфигурацию от образов контейнеров, что облегчает изменение настроек без пересборки образа. **Secret** — это аналогичный объект, но предназначенный для хранения *чувствительных* данных, таких как пароли, OAuth-токены, SSH-ключи. Данные в Secret хранятся в base64-кодировке (не шифрование!). Они могут монтироваться в Pod как том или передаваться как переменные среды. ConfigMap и Secret предоставляют централизованный и безопасный (в случае Secret) способ управления конфигурацией, соответствующей принципам Twelve-Factor App.

### 29. Опишите жизненный цикл приложения в Kubernetes.
1) **Разработка:** Приложение упаковывается в образ Docker и помещается в реестр. 2) **Описание:** Разработчик создает манифесты (YAML-файлы), описывающие объекты Kubernetes: Deployment (желаемое состояние приложения), Service, ConfigMap и т.д. 3) **Развертывание:** Манифесты применяются командой `kubectl apply`. Контроллер Deployment создает набор Pod'ов (ReplicaSet). 4) **Запуск:** Планировщик (Scheduler) назначает Pod'ам узлы (Nodes), где запускаются контейнеры. 5) **Работа и мониторинг:** Kubelet на узле следит за состоянием Pod'а. Контроллеры постоянно сверяют текущее состояние с желаемым. 6) **Обновление:** Deployment может выполнить rolling update, постепенно заменяя Pod'ы на новые версии без простоя. 7) **Масштабирование:** Количество реплик Pod'ов можно изменить вручную или автоматически (HPA). 8) **Откат:** В случае проблем можно откатиться к предыдущей версии Deployment.

### 30. Какие архитектурные подходы (монолит, микросервисы, serverless) лучше использовать для стартапа, крупного банка и мобильного приложения? Обоснуйте выбор.
*   **Стартап:** **Монолит.** Позволяет быстро выйти на рынок с минимальной сложностью. Небольшая команда может эффективно работать над одним кодом. Нет накладных расходов на распределенные системы. Микросервисы добавят ненужную сложность на раннем этапе.
*   **Крупный банк:** **Микросервисы (или гибрид).** У банка есть множество сложных, независимых систем (платежи, кредиты, CRM), над которыми работают сотни разработчиков. Микросервисы позволяют независимо разрабатывать, масштабировать и обновлять эти системы. Строгие требования к безопасности и комплаенсу также проще реализовать в изолированных сервисах.
*   **Мобильное приложение (бэкенд):** **Serverless (BaaS/FaaS) или микросервисы.** Для типичного мобильного бэкенда с переменной нагрузкой (пики при публикации контента) serverless идеален: нет управления серверами, автоскейлинг, оплата по запросам. Для сложного приложения с четкими контекстами (лента, чат, платежи) подойдут микросервисы.

### 31. Что такое HDFS и каковы его основные компоненты?
HDFS (Hadoop Distributed File System) — это распределенная файловая система, предназначенная для хранения очень больших объемов данных (петабайты) на кластерах обычного оборудования. Она обеспечивает высокую пропускную способность при доступе к данным. **Основные компоненты:** 1) **NameNode (главный узел):** Один (или два для HA) сервер, который управляет метаданными файловой системы (структура каталогов, информация о блоках файлов, их местоположении). Он не хранит сами данные. 2) **DataNode (рабочие узлы):** Множество серверов, которые непосредственно хранят данные. Файлы разбиваются на блоки (обычно 128/256 МБ), которые реплицируются на несколько DataNodes. 3) **Secondary NameNode (не standby!):** Выполняет периодическое объединение журналов изменений (edit logs) с основным образом файловой системы (fsimage), чтобы не перегружать NameNode.

### 32. Объясните роль NameNode и DataNode в архитектуре HDFS.
**NameNode** — это «мозг» HDFS. Он хранит и управляет всей метаинформацией (namespace): иерархией файлов и папок, а также отображением файлов на блоки данных и блоков на DataNodes. Клиент, желающий прочитать файл, сначала обращается к NameNode, чтобы получить список блоков и их расположение (адреса DataNodes). NameNode не участвует непосредственно в передаче данных, что позволяет ему обслуживать множество клиентов. **DataNode** — это «рабочая лошадка», которая хранит фактические блоки данных на своих локальных дисках. Они постоянно отправляют NameNode отчеты о состоянии и списке хранимых блоков (heartbeats и block reports). При чтении клиент обращается напрямую к DataNode за нужным блоком. Отказ DataNode обнаруживается по пропаже heartbeat, после чего NameNode инициирует репликацию потерянных блоков с других узлов.

### 33. Как обеспечивается отказоустойчивость в HDFS?
1) **Репликация данных:** По умолчанию каждый блок данных реплицируется на 3 разных DataNode (можно настраивать). Это защищает от потери данных при отказе диска или целого сервера. 2) **Отказоустойчивость NameNode (High Availability):** В режиме HA запускаются два NameNode: активный (Active) и резервный (Standby). Standby постоянно синхронизирует свое состояние с Active. При сбое Active автоматически происходит быстрый failover на Standby. 3) **Механизм Heartbeat и Block Report:** DataNode постоянно шлют сигналы NameNode. Если NameNode не получает heartbeat от DataNode в течение определенного времени, он помечает узел как мертвый и реплицирует его блоки на другие живые узлы. 4) **Восстановление из чекпойнтов:** Secondary NameNode помогает создавать резервные копии метаданных NameNode (fsimage).

### 34. Опишите принцип работы модели MapReduce. Приведите пример.
MapReduce — это модель программирования для параллельной обработки больших наборов данных на кластере. Она состоит из двух основных этапов. **Этап Map (отображение):** Каждый узел обрабатывает свою порцию входных данных и выдает набор промежуточных пар ключ-значение. Например, для подсчета слов в тексте: функция Map принимает строку и выдает пары `(слово, 1)`. **Этап Shuffle and Sort:** Фреймворк группирует все промежуточные значения по одинаковым ключам и отправляет их на узлы для этапа Reduce. **Этап Reduce (свертка):** Узлы получают все значения для одного ключа, обрабатывают их (например, суммируют) и выдают финальный результат. В примере со словами: Reduce получает `(слово, [1,1,1,...])` и выдает `(слово, сумма)`. Это позволяет обрабатывать петабайты данных на тысячах серверов.

### 35. Что такое YARN и какова его роль в экосистеме Hadoop?
YARN (Yet Another Resource Negotiator) — это фреймворк управления ресурсами кластера и планирования задач, появившийся в Hadoop 2.0. Он отделил функцию управления ресурсами от модели обработки данных MapReduce. **Его роль:** YARN превратил Hadoop из исключительно MapReduce-платформы в *многозадачную* операционную систему для больших данных. Он управляет ресурсами всех узлов кластера (CPU, память) и распределяет их между различными приложениями: MapReduce, Spark, Hive, Flink и др. YARN состоит из **ResourceManager** (главный, управляющий всем кластером) и **NodeManager** (на каждом узле, управляющий локальными ресурсами). Это позволило запускать разнородные workloads на одном кластере, повысив его утилизацию и гибкость.

### 36. Какие инструменты входят в экосистему Hadoop? Кратко охарактеризуйте Pig, Hive, HBase.
Экосистема Hadoop огромна. **Apache Pig:** Платформа для анализа больших данных с использованием высокоуровневого языка сценариев Pig Latin. Он компилируется в последовательность MapReduce-заданий, скрывая сложность Java-кода от аналитика. **Apache Hive:** Система хранилища данных (data warehouse), которая предоставляет SQL-подобный язык запросов (HiveQL) для чтения, записи и управления большими наборами данных в HDFS. HiveQL транслируется в задания MapReduce или Tez/Spark. **Apache HBase:** Распределенная, масштабируемая NoSQL база данных, работающая поверх HDFS. Предоставляет случайный доступ в реальном времени к большим данным (в противовес пакетной обработке MapReduce) по модели «ключ-значение» или «колоночное хранилище».

### 37. Что такое Oozie и для чего он используется в Hadoop?
Apache Oozie — это система **оркестрации рабочих процессов (workflow scheduler)** для управления задачами Hadoop. Она используется для планирования и координации выполнения сложных, многокомпонентных заданий (jobs), которые могут состоять из последовательных, параллельных или условных шагов. Например, рабочий процесс может включать: сначала запуск скрипта Pig для очистки данных, затем задание Hive для агрегации, потом запуск MapReduce-программы и отправку email-уведомления. Oozie позволяет описывать такие workflows в XML (workflow.xml) и запускать их по расписанию (координатор) или при появлении данных (bundle). Это ключевой инструмент для автоматизации ETL-процессов и конвейеров данных в Hadoop-экосистеме.

### 38. Опишите архитектуру Apache Kafka и её преимущества.
Apache Kafka — это распределенная платформа потоковой передачи событий (streaming), работающая как отказоустойчивый, горизонтально масштабируемый publish-subscribe messaging system. **Архитектура:** Данные организуются в **топики (topics)**. Топики делятся на **партиции (partitions)** для параллелизма и распределяются по **брокерам (brokers,** серверы Kafka). **Производители (producers)** публикуют записи (records) в топики. **Потребители (consumers)** (объединенные в группы) читают записи. **ZooKeeper** (или в новых версиях KRaft) управляет метаданными брокеров и контроллера. **Преимущества:** 1) **Высокая пропускная способность** при низкой задержке. 2) **Масштабируемость:** Легко добавлять брокеры. 3) **Отказоустойчивость:** Данные реплицируются между брокерами. 4) **Надежность:** Сообщения сохраняются на диске и могут хранится долго. 5) **Поддержка множества потребителей** (модель pub-sub).

### 39. Как Zookeeper решает проблему координации в распределенных системах?
ZooKeeper — это централизованная служба для распределенных систем, предоставляющая: распределенное хранение конфигурации, синхронизацию (coordination) и группировку (naming). Он решает проблемы координации через простую и надежную иерархическую систему узлов **Znode** (похожа на файловую систему). С помощью этих Znode реализуются ключевые примитивы: 1) **Управление конфигурацией:** Хранение и распространение общих настроек (например, список активных брокеров Kafka). 2) **Выбор лидера (Leader election):** Узлы могут создать эфемерный Znode, и тот, кто создаст первым, становится лидером. 3) **Блокировки (Locks):** Для реализации распределенных мьютексов и координации доступа к ресурсам. 4) **Служба именования (Naming Service) и обнаружение сервисов (Service discovery).** ZooKeeper гарантирует последовательную согласованность (linearizable writes) и высокую доступность при наличии кворума живых серверов.

### 40. Какие типы узлов (znodes) поддерживает Zookeeper и для чего они используются?
ZooKeeper поддерживает два основных типа узлов (Znode): 1) **Постоянные (Persistent):** Созданный Znode существует до тех пор, пока его явно не удалят. Используется для хранения долгосрочных данных, например, конфигурации кластера или метаданных. 2) **Эфемерные (Ephemeral):** Znode существует только пока активна сессия клиента, который его создал. При разрыве соединения Znode автоматически удаляется. Это ключевой механизм для **обнаружения сбоев (failure detection)** и **выбора лидера (leader election)**, так как исчезновение узла сигнализирует об отказе сервиса. Оба типа могут быть **последовательными (Sequential)**, что означает, что ZooKeeper автоматически добавляет уникальный монотонно возрастающий номер к имени Znode. Это полезно для реализации блокировок (locks) и упорядочивания событий.

### 41. Что такое нейронная сеть и как устроен простейший нейрон (модель МакКаллока-Питтса)?
Нейронная сеть — это вычислительная модель, вдохновленная биологическими нейронными сетями мозга, состоящая из множества взаимосвязанных простых процессоров (нейронов). Простейшая модель искусственного нейрона — модель **МакКаллока-Питтса (1943)**. Она принимает несколько бинарных входных сигналов (x1, x2, ..., xn), каждому из которых сопоставлен вес (w1, w2, ..., wn), имитирующий силу синаптической связи. Нейрон вычисляет взвешенную сумму входов: `S = Σ (wi * xi)`. Затем эта сумма сравнивается с пороговым значением (threshold) θ. Если S >= θ, нейрон «активируется» и выдает выходной сигнал 1, иначе — 0. Это бинарная, детерминированная модель, которая может выполнять простые логические функции (И, ИЛИ), но не способна к обучению, так как не имеет механизма настройки весов.

### 42. Объясните принцип работы многослойного перцептрона и алгоритма обратного распространения ошибки.
**Многослойный перцептрон (MLP)** — это нейронная сеть прямого распространения (feedforward), состоящая из входного, одного или нескольких скрытых слоев и выходного слоя нейронов. Каждый нейрон связан со всеми нейронами предыдущего слоя. Нейроны используют нелинейную **функцию активации** (сигмоида, ReLU), что позволяет сети аппроксимировать сложные нелинейные функции. **Алгоритм обратного распространения ошибки (Backpropagation)** — это метод обучения MLP. 1) **Прямой проход:** Входные данные подаются на сеть, вычисляется выход. 2) **Вычисление ошибки:** Сравнивается выход сети с правильным ответом (целевым значением) с помощью функции потерь (loss function). 3) **Обратный проход:** Ошибка *распространяется назад* по сети от выходного слоя к входному. На этом этапе вычисляется **градиент** функции потерь по каждому весу сети (правило цепочки). 4) **Обновление весов:** Веса корректируются в сторону, противоположную градиенту (градиентный спуск), чтобы минимизировать ошибку.

### 43. В чём состоит проблема исчезающего градиента в рекуррентных нейронных сетях?
Проблема исчезающего градиента возникает при обучении глубоких нейронных сетей, особенно рекуррентных (RNN), с помощью backpropagation. При обратном распространении ошибки через множество слоев (или через много временных шагов в RNN) градиенты (производные) непрерывно перемножаются по правилу цепочки. Если эти производные (часто от сигмоидной или гиперболической функции активации) меньше 1, их последовательное перемножение приводит к **экспоненциальному затуханию** градиента. В итоге градиенты для весов ранних слоев (или первых шагов в последовательности) становятся исчезающе малыми. Это означает, что эти веса практически не обновляются, и сеть не может научиться долгосрочным зависимостям в данных — она «забывает» то, что было в начале длинной последовательности.

### 44. Что такое LSTM и как он решает проблему долгосрочных зависимостей?
LSTM (Long Short-Term Memory) — это особый тип архитектуры рекуррентных нейронных сетей (RNN), специально разработанный для борьбы с проблемой исчезающего градиента и обучения долгосрочным зависимостям. Ключевое нововведение — **ячейка памяти (cell state)**, которая проходит через всю цепочку LSTM практически без изменений, как «конвейерная лента». Информация добавляется или удаляется из этого состояния с помощью трех **вентилей (gates)**, управляемых сигмоидными слоями (выдают значения от 0 до 1): 1) **Forget gate** решает, какую информацию выбросить из состояния. 2) **Input gate** решает, какую новую информацию записать в состояние. 3) **Output gate** решает, что на основе текущего состояния выдать на выход. Эти вентили позволяют LSTM целенаправленно сохранять информацию на долгое время, что критично для задач перевода, генерации текста и анализа временных рядов.

### 45. Как работает метод опорных векторов (SVM)? Приведите пример его использования.
SVM (Support Vector Machine) — это алгоритм для задач классификации (и регрессии). Его цель — найти оптимальную разделяющую гиперплоскость в пространстве признаков, которая максимизирует **зазор (margin)** между двумя классами. Margin — это расстояние от гиперплоскости до ближайших точек каждого класса, которые называются **опорными векторами (support vectors)**. SVM ищет гиперплоскость, которая не просто разделяет классы, а делает это с максимальным запасом, что повышает обобщающую способность. Для нелинейно разделимых данных используется **трюк с ядром (kernel trick)**: данные нелинейно отображаются в пространство более высокой размерности, где они становятся линейно разделимыми, без явного вычисления этого преобразования. **Пример использования:** Классификация изображений (например, распознавание рукописных цифр), биоинформатика (классификация белков), текстовая классификация (спам/не спам).

### 46. Опишите алгоритм кластеризации K-means. Каковы его достоинства и недостатки?
**Алгоритм K-means** — это итеративный метод кластеризации, который разбивает данные на K заранее заданных непересекающихся кластеров. **Шаги:** 1) Инициализация: Случайный выбор K точек в качестве начальных центроидов кластеров. 2) **Назначение (Assignment):** Каждая точка данных назначается ближайшему (по евклидову расстоянию) центроиду. 3) **Обновление (Update):** Для каждого кластера вычисляется новый центроид как среднее арифметическое всех точек, назначенных этому кластеру. 4) Повтор шагов 2-3 до сходимости (когда центроиды перестают значительно меняться). **Достоинства:** Простота и скорость работы, легко интерпретировать результат. **Недостатки:** Необходимость заранее задавать K, чувствительность к начальным центроидам и выбросам, плохо работает с кластерами сложной формы и разного размера/плотности.

### 47. Что такое метод главных компонент (PCA) и для чего он используется?
Метод главных компонент (PCA — Principal Component Analysis) — это техника **снижения размерности** данных. Его цель — преобразовать исходный набор признаков (часто коррелированных) в новый набор некоррелированных признаков, называемых **главными компонентами**, которые упорядочены по убыванию дисперсии, которую они объясняют. Первая главная компонента (PC1) соответствует направлению максимальной дисперсии в данных. Вторая (PC2) — направлению максимальной дисперсии, ортогональному первой, и так далее. **Для чего используется:** 1) **Сокращение данных:** Уменьшение числа признаков для ускорения работы алгоритмов ML и борьбы с проклятием размерности. 2) **Визуализация:** Проекция данных на первые 2-3 главные компоненты для построения графиков. 3) **Выделение скрытых паттернов и шумоподавление,** так как последние компоненты часто соответствуют шуму.

### 48. Как оценивается качество кластеризации? Назовите основные метрики (Accuracy, Precision, Recall, ROC-AUC).
**Важно:** Accuracy, Precision, Recall, ROC-AUC — это метрики для оценки задач **классификации с учителем**, где есть правильные ответы. Для **кластеризации (обучение без учителя)** истинные метки обычно отсутствуют, и используются другие метрики. **Метрики для кластеризации:** 1) **Внутрикластерное расстояние (Inertia/Within-cluster SSE):** Сумма квадратов расстояний от точек до центроида их кластера. Чем меньше, тем компактнее кластеры. 2) **Силуэт (Silhouette Score):** Оценивает, насколько точка похожа на свой кластер по сравнению с другими кластерами. Диапазон от -1 до 1, чем выше, тем лучше. 3) **Внешние метрики (если истинные метки известны):** Adjusted Rand Index (ARI), Normalized Mutual Information (NMI) — сравнивают полученные кластеры с истинными.

### 49. Что такое самоорганизующиеся карты Кохонена (SOM)? Приведите пример их применения.
Самоорганизующаяся карта Кохонена (SOM) — это тип искусственной нейронной сети, обучающейся **без учителя**, которая используется для кластеризации и визуализации многомерных данных в пространство меньшей размерности (обычно 2D). SOM состоит из нейронов, расположенных на решетке (карте). Каждый нейрон имеет вектор весов той же размерности, что и входные данные. В процессе обучения на каждый входной вектор находится **нейрон-победитель (Best Matching Unit, BMU)** — нейрон с наиболее близкими весами. Затем веса BMU и его соседей на карте подтягиваются к входному вектору. В результате нейроны, близкие на карте, реагируют на похожие входные данные. **Пример применения:** Визуализация и анализ высокомерных данных, например, сегментация клиентов по множеству признаков, группировка генов по паттернам экспрессии, сжатие изображений.

### 50. Как работает алгоритм растущего нейронного газа (GNG)?
Алгоритм Растущего Нейронного Газа (GNG) — это адаптивный алгоритм кластеризации, который строит топологическую карту данных «на лету», без предварительного задания числа кластеров. **Принцип работы:** 1) Начинается с небольшого числа нейронов (узлов). 2) На каждой итерации подается входной сигнал (точка данных). 3) Находятся два ближайших нейрона (победитель и второй). 4) Победитель и его топологические соседи сдвигаются в сторону входного сигнала. 5) Связь между победителем и вторым нейроном усиливается, возраст других связей победителя увеличивается. 6) Старые связи удаляются. 7) Периодически вставляются новые нейроны в области с наибольшей ошибкой. 8) Алгоритм останавливается по заданному критерию. GNG эффективно отражает топологию и плотность данных.

### 51. Какие методы обучения нейронных сетей, кроме обратного распространения, вы знаете?
1) **Стохастический градиентный спуск (SGD) и его варианты:** Хотя backpropagation вычисляет градиенты, SGD — это метод их использования для обновления весов. К его вариантам относятся: Momentum, Adagrad, RMSprop, Adam (наиболее популярен). 2) **Метод сопряженных градиентов (Conjugate Gradient).** 3) **Методы второго порядка (Second-order methods):** Используют матрицу Гессе (вторые производные), например, метод Ньютона. Они эффективны, но требуют много вычислений. 4) **Генетические алгоритмы (Evolutionary algorithms):** Оптимизация весов как эволюция популяции. 5) **Обучение с подкреплением (Reinforcement Learning):** Например, Deep Q-Networks (DQN) для обучения агента в среде. 6) **Независимое обучение автокодировщиков (например, для глубоких сетей).** 7) **Метод обратного распространения через время (BPTT)** — специализация для RNN.

### 52. Что такое TensorFlow и как он используется для построения нейросетей?
TensorFlow — это открытая библиотека машинного обучения и численных вычислений, разработанная Google, с акцентом на **глубокое обучение (deep learning)**. Она используется как платформа для построения и обучения нейронных сетей. Работа ведется путем создания **вычислительного графа (computational graph)**, где узлы — это математические операции (тензорные, отсюда и название), а ребра — многомерные массивы данных (тензоры). Пользователь на языке Python определяет архитектуру сети (последовательность слоев), функцию потерь и оптимизатор. Затем TensorFlow автоматически вычисляет градиенты (с помощью **AutoDiff**) и выполняет оптимизацию. Он поддерживает распределенные вычисления на CPU, GPU и TPU, что позволяет обучать очень большие модели. Также есть высокоуровневый API Keras для быстрого прототипирования.

### 53. Как можно визуализировать результаты кластеризации с помощью тепловых карт?
Тепловая карта (heatmap) — это графическое представление данных, где значения матрицы отображаются в виде цветов (оттенков). Для визуализации кластеризации тепловые карты используются следующим образом: 1) Данные (объекты-признаки) упорядочиваются в соответствии с принадлежностью к кластерам, полученным алгоритмом (например, K-means). Строки таблицы данных сортируются по меткам кластера. 2) Часто применяется **иерархическая кластеризация** как для строк (объектов), так и для столбцов (признаков), чтобы сгруппировать похожие объекты и признаки рядом. Это выявляет паттерны. 3) Полученная матрица (или матрица средних значений признаков по кластерам) отображается как heatmap, где цвет ячейки соответствует значению признака для объекта (например, от синего для низких значений до красного для высоких). Это позволяет увидеть, какие признаки характеризуют каждый кластер.

### 54. Опишите алгоритм KNN (K ближайших соседей) и его применение.
KNN (K-Nearest Neighbors) — это простой, **ленивый** (не строит модель во время обучения) алгоритм для задач классификации и регрессии. **Принцип работы:** Для классификации нового объекта: 1) Найти в обучающей выборке K объектов, наиболее близких к нему по выбранной метрике расстояния (обычно евклидова). 2) Определить класс нового объекта путем **голосования** — за какой класс проголосовало большинство среди его K соседей. Для регрессии — вычислить среднее значение целевой переменной соседей. **Ключевые параметры:** K (число соседей) и метрика расстояния. **Применение:** Рекомендательные системы (похожие пользователи/товары), классификация текстов, финансы (прогнозирование кредитного рейтинга), медицина (диагностика). Главные недостатки: медленная классификация на больших данных и чувствительность к разным масштабам признаков (требует нормализации).

### 55. Как Hadoop обеспечивает обработку больших данных в распределенной среде?
Hadoop обеспечивает обработку за счет двух ключевых компонентов: **HDFS** и **MapReduce** (или другие движки поверх YARN). 1) **Хранение:** HDFS разбивает огромные файлы на блоки (128/256 МБ) и распределяет их по множеству узлов кластера с репликацией для отказоустойчивости. 2) **Обработка «данные рядом с кодом»:** Принцип **data locality** — задача MapReduce отправляется на тот узел, где находятся обрабатываемые данные, минимизируя сетевой трафик. 3) **Параллельная обработка:** Задача разбивается на множество независимых подзадач (map- и reduce-задания), которые выполняются параллельно на разных узлах кластера. 4) **Управление ресурсами и отказоустойчивость:** YARN управляет ресурсами, а фреймворк перезапускает упавшие задачи на других узлах. Это позволяет обрабатывать петабайты данных на дешевом, стандартном оборудовании.

### 56. Что такое репликация данных в HDFS и как она настраивается?
Репликация данных в HDFS — это процесс создания нескольких копий (реплик) каждого блока данных и хранения их на разных DataNodes. Это основной механизм обеспечения отказоустойчивости и доступности. **Как настраивается:** Коэффициент репликации (replication factor) по умолчанию равен 3. Его можно задать глобально в конфигурационном файле `hdfs-site.xml` (параметр `dfs.replication`), а также для отдельных файлов или директорий через API HDFS или командную строку (например, `hadoop fs -setrep -w 5 /path/to/file`). При записи файла клиентская библиотека HDFS получает от NameNode список DataNodes для каждой реплики блока. Первая реплика пишется на локальный узел (если клиент — DataNode), вторая — на узел в другой стойке (rack), третья — на другой узел в той же стойке, что и вторая (политика размещения). Это обеспечивает устойчивость к отказу узла и всей стойки.

### 57. Какой язык программирования чаще всего используется для работы с Hadoop? Можно ли использовать другие языки?
**Первичным** языком для нативной разработки под Hadoop (написание MapReduce-заданий) является **Java**, так как сам Hadoop написан на Java. Однако экосистема Hadoop предоставляет множество способов использовать другие языки. 1) **Hadoop Streaming:** Позволяет писать map- и reduce-функции на любом языке (Python, Ruby, Bash), которые читают из stdin и пишут в stdout. 2) **Hive (HiveQL):** SQL-подобный язык для запросов. 3) **Pig (Pig Latin):** Скриптовый язык высокого уровня. 4) **Apache Spark:** Поддерживает Scala (родной), Python (PySpark), Java и R для обработки данных поверх HDFS, часто заменяя MapReduce. Таким образом, для сложной низкоуровневой логики нужна Java, но для анализа данных можно эффективно использовать Python (через PySpark, Streaming) или SQL (через Hive).

### 58. Что такое HiveQL и чем он отличается от SQL?
HiveQL (Hive Query Language) — это декларативный SQL-подобный язык запросов, используемый в Apache Hive для анализа данных в HDFS. **Сходства:** Поддерживает знакомый синтаксис SELECT, JOIN, GROUP BY, агрегатные функции, подзапросы. **Отличия:** 1) **HiveQL предназначен для пакетной обработки больших данных,** а не для интерактивных транзакций с низкой задержкой (OLTP). 2) **Отсутствие поддержки UPDATE и DELETE** в ранних версиях (в Hive 0.14+ появились, но ограниченно, т.к. HDFS — файловая система для добавления). 3) **Расширения для работы со сложными структурами данных:** Массивы (ARRAY), Карты (MAP), Структуры (STRUCT). 4) **Оптимизация под MapReduce/Tez/Spark:** Запросы транслируются в серию заданий. 5) **Семантика Hive:** Строгая типизация, явное приведение типов. 6) **Поддержка пользовательских функций (UDF)** на Java и Python.

### 59. Как Zookeeper помогает в выборе лидера (leader election) в распределенных системах?
ZooKeeper предоставляет надежный примитив для выбора лидера с помощью **эфемерных последовательных узлов (Ephemeral Sequential Znodes)**. **Процесс:** 1) Все кандидаты на роль лидера создают эфемерный последовательный Znode с одинаковым префиксом (например, `/election/node_`). ZooKeeper автоматически добавляет уникальный номер (например, `node_0001`, `node_0002`). 2) Кандидат, создавший Znode с **наименьшим порядковым номером**, объявляется лидером. 3) Остальные кандидаты «следят» (watch) за Znode с предыдущим по порядку номером. 4) Если текущий лидер отказывает (его сессия разрывается, и его эфемерный Znode удаляется), ZooKeeper уведомляет кандидата, следившего за этим узлом. 5) Этот кандидат проверяет, стал ли он теперь узлом с наименьшим номером, и если да, становится новым лидером. Этот механизм гарантирует, что лидер всегда будет выбран и система автоматически переживет отказы.

### 60. Приведите пример использования нейронной сети для анализа текстовых данных (например, отзывов).
Типичная задача — **анализ тональности (Sentiment Analysis)** отзывов на фильмы. 1) **Подготовка данных:** Отзывы очищаются (удаление стоп-слов, пунктуации), токенизируются (разбиваются на слова). 2) **Векторизация текста:** Каждому слову ставится в соответствие вектор (эмбеддинг), например, с помощью Word2Vec, GloVe или непосредственного обучения эмбеддинг-слоя. Вся последовательность слов отзыва преобразуется в матрицу векторов. 3) **Архитектура сети:** Используется рекуррентная нейронная сеть (например, LSTM или BiLSTM), которая способна учитывать контекст и порядок слов в последовательности. Слой эмбеддингов -> LSTM-слой -> Dense-слой с активацией sigmoid (для бинарной классификации «положительный»/«отрицательный»). 4) **Обучение:** Сеть обучается на размеченных отзывах, минимизируя бинарную кросс-энтропию. 5) **Результат:** Обученная модель предсказывает вероятность положительного отзыва для новых текстов.